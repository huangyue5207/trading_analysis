"""
å¸å®‰Kçº¿æ•°æ®åˆ†æå’Œå¯è§†åŒ–è„šæœ¬

åŠŸèƒ½ï¼š
1. å°†ä»»æ„æ—¶é—´ç²’åº¦çš„Kçº¿æ‹†åˆ†åˆ°1ç§’Kçº¿ï¼Œè®¡ç®—æ¯æ ¹1ç§’Kçº¿çš„å…¸å‹ä»·æ ¼(high+low+close)/3 * è¯¥1ç§’Kçº¿çš„æˆäº¤é‡ï¼Œ
   ç„¶åå¯¹æ‰€æœ‰1ç§’Kçº¿çš„è®¡ç®—ç»“æœæ±‚å’Œï¼Œæœ€åé™¤ä»¥å½“å‰ç²’åº¦Kçº¿çš„æ€»æˆäº¤é‡
2. åœ¨Kçº¿å›¾ä¸­ç»˜åˆ¶è¯¥ç»“æœæ›²çº¿
3. è®¡ç®—æ¯æ ¹Kçº¿çš„(open+close)/2å¹¶åœ¨Kçº¿å›¾ä¸­ç»˜åˆ¶
4. ä½¿ç”¨å¸å®‰APIè·å–æ•°æ®
"""

import requests
import pandas as pd
import numpy as np
import importlib
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
from typing import Optional, List, Dict
import time
import os
import json

# è®¾ç½®matplotlibæ”¯æŒä¸­æ–‡
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


class BinanceKlineData:
    """å¸å®‰Kçº¿æ•°æ®è·å–ç±»"""
    
    def __init__(self, csv_file_path: str):
        self.base_url = "https://api.binance.com/api/v3"
        self.session = requests.Session()
        self.csv_file_path = csv_file_path
        
        # å¸å®‰æ—¶é—´é—´éš”æ˜ å°„åˆ°ç§’æ•°
        self.interval_seconds = {
            '1s': 1,
            '1m': 60,
            '3m': 180,
            '5m': 300,
            '15m': 900,
            '30m': 1800,
            '1h': 3600,
            '2h': 7200,
            '4h': 14400,
            '6h': 21600,
            '8h': 28800,
            '12h': 43200,
            '1d': 86400,
            '3d': 259200,
            '1w': 604800,
            '1M': 2592000
        }

        self.history_periods = {
            '15m': 3,
            '1h': 12,
            '4h': 48,
            '1d': 192
        }
    
    def get_kline_data(self,
                      symbol: str = "BTCUSDT",
                      interval: str = "1h",
                      start_time: Optional[datetime] = None,
                      end_time: Optional[datetime] = None,
                      limit: int = 1000) -> pd.DataFrame:
        """
        è·å–å¸å®‰Kçº¿æ•°æ®
        
        Args:
            symbol: äº¤æ˜“å¯¹ï¼Œå¦‚ 'BTCUSDT', 'ETHUSDT'
            interval: æ—¶é—´é—´éš”ï¼Œå¦‚ '1m', '5m', '1h', '1d'
            start_time: å¼€å§‹æ—¶é—´ (datetimeå¯¹è±¡)
            end_time: ç»“æŸæ—¶é—´ (datetimeå¯¹è±¡)
            limit: å•æ¬¡è¯·æ±‚æœ€å¤§æ•°é‡ï¼ˆé»˜è®¤1000ï¼‰
            
        Returns:
            pandas.DataFrame: åŒ…å«OHLCVæ•°æ®çš„DataFrame
        """
        
        url = f"{self.base_url}/klines"
        all_data = []
        
        try:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šæ—¶é—´ï¼Œé»˜è®¤è·å–æœ€è¿‘çš„æ•°æ®
            if not start_time:
                start_time = datetime.now() - timedelta(days=7)
            if not end_time:
                end_time = datetime.now()
            
            # è½¬æ¢ä¸ºæ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
            start_ms = int(start_time.timestamp() * 1000)
            end_ms = int(end_time.timestamp() * 1000)
            current_start = start_ms
            
            # åˆ†æ‰¹è·å–æ•°æ®ï¼ˆå¸å®‰APIé™åˆ¶å•æ¬¡æœ€å¤š1000æ¡ï¼‰
            while current_start < end_ms:
                params = {
                    'symbol': symbol,
                    'interval': interval,
                    'startTime': current_start,
                    'endTime': end_ms,
                    'limit': limit
                }
                
                response = self.session.get(url, params=params)
                response.raise_for_status()
                data = response.json()
                
                if not data:
                    break
                
                all_data.extend(data)
                
                # æ›´æ–°èµ·å§‹æ—¶é—´ï¼ˆä½¿ç”¨æœ€åä¸€æ¡æ•°æ®çš„æ—¶é—´ï¼‰
                last_time = data[-1][0]  # ç¬¬ä¸€æ¡æ˜¯å¼€ç›˜æ—¶é—´æˆ³
                if last_time >= end_ms:
                    break
                
                current_start = last_time + 1
                
                # é˜²æ­¢APIé™é€Ÿ
                time.sleep(0.1)
            
            if not all_data:
                print(f"æœªè·å–åˆ° {symbol} çš„æ•°æ®")
                return pd.DataFrame()
            
            # å¸å®‰è¿”å›çš„æ•°æ®æ ¼å¼: 
            # [Open time, Open, High, Low, Close, Volume, Close time, Quote volume, 
            #  Trades, Taker buy base volume, Taker buy quote volume, Ignore]
            df = pd.DataFrame(all_data, columns=[
                'open_time', 'open', 'high', 'low', 'close', 'volume',
                'close_time', 'quote_volume', 'trades', 'taker_buy_base_volume',
                'taker_buy_quote_volume', 'ignore'
            ])
            
            # è½¬æ¢æ—¶é—´æˆ³ä¸ºdatetime
            df['timestamp'] = pd.to_datetime(df['open_time'], unit='ms')
            df['close_time'] = pd.to_datetime(df['close_time'], unit='ms')

            # å°†df['timestamp']è½¬æˆutc+8æ—¶åŒº
            df['timestamp'] = df['timestamp'].dt.tz_localize('UTC').dt.tz_convert('UTC+08:00')
            
            # è½¬æ¢æ•°å€¼ç±»å‹
            numeric_cols = ['open', 'high', 'low', 'close', 'volume', 'quote_volume']
            for col in numeric_cols:
                df[col] = pd.to_numeric(df[col], errors='coerce')
            
            # é€‰æ‹©éœ€è¦çš„åˆ—
            df = df[['timestamp', 'open', 'high', 'low', 'close', 'volume', 'quote_volume']]
            df = df.sort_values('timestamp').reset_index(drop=True)
            
            print(f"æˆåŠŸè·å– {symbol} çš„ {len(df)} æ¡Kçº¿æ•°æ®")
            print(f"æ—¶é—´èŒƒå›´: {df['timestamp'].min()} åˆ° {df['timestamp'].max()}")
            
            return df
            
        except requests.RequestException as e:
            print(f"è·å–Kçº¿æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
        except Exception as e:
            print(f"å¤„ç†æ•°æ®æ—¶å‡ºé”™: {e}")
            return pd.DataFrame()
    
    def calculate_typical_price_volume(self, df: pd.DataFrame) -> float:
        """
        å°†Kçº¿æ‹†åˆ†åˆ°1ç§’çº§åˆ«ï¼Œè®¡ç®—å…¸å‹ä»·æ ¼*æˆäº¤é‡å¹¶æ±‡æ€»ï¼Œæœ€åé™¤ä»¥æ€»æˆäº¤é‡
        
        Args:
            df: åŒ…å«OHLCVæ•°æ®çš„DataFrame
            
        Returns:
            float: æ­£å‘ä¸è´Ÿå‘å…¸å‹ä»·æ ¼æˆäº¤é‡å·®ï¼ˆå‡€æµå…¥ï¼‰
        """
        positive_price_volume = 0
        negative_price_volume = 0
        
        for idx, row in df.iterrows():
            # è·å–å½“å‰Kçº¿çš„æ—¶é—´èŒƒå›´
            start_time = row['timestamp']
            
            # ç¡®å®šæ—¶é—´ç²’åº¦ï¼ˆç§’ï¼‰
            if idx < len(df) - 1:
                next_time = df.iloc[idx + 1]['timestamp']
                interval_seconds = int((next_time - start_time).total_seconds())
            else:
                # å¦‚æœæ˜¯æœ€åä¸€æ¡ï¼Œä½¿ç”¨å‰ä¸€æ¡çš„é—´éš”
                if idx > 0:
                    prev_time = df.iloc[idx - 1]['timestamp']
                    interval_seconds = int((start_time - prev_time).total_seconds())
                else:
                    interval_seconds = 3600  # é»˜è®¤1å°æ—¶
            
            # è®¡ç®—å…¸å‹ä»·æ ¼
            typical_price = (row['high'] + row['low'] + row['close']) / 3
            
            # å½“å‰Kçº¿çš„æ€»æˆäº¤é‡
            total_volume = row['volume']
            
            # å°†å½“å‰Kçº¿çš„æˆäº¤é‡å‡åŒ€åˆ†é…åˆ°1ç§’Kçº¿
            # å‡è®¾æˆäº¤é‡åœ¨æ—¶é—´ä¸Šæ˜¯å‡åŒ€åˆ†å¸ƒçš„
            volume_per_second = total_volume / interval_seconds if interval_seconds > 0 else 0
            
            # è®¡ç®—æ¯æ ¹1ç§’Kçº¿çš„å…¸å‹ä»·æ ¼*æˆäº¤é‡
            # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬å‡è®¾å…¸å‹ä»·æ ¼åœ¨æ•´ä¸ªKçº¿æœŸé—´ä¿æŒä¸å˜
            # å®é™…æƒ…å†µä¸‹ï¼Œ1ç§’å†…çš„ä»·æ ¼ä¼šåœ¨highå’Œlowä¹‹é—´å˜åŒ–
            # ä½†ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬ä½¿ç”¨å…¸å‹ä»·æ ¼ä½œä¸ºå¹³å‡å€¼
            typical_price_volume_per_second = typical_price * volume_per_second

            # if row['close'] >= row['open']:
            #     positive_price_volume += typical_price_volume_per_second
            # else:
            #     negative_price_volume += typical_price_volume_per_second
            
            if row['close'] > row['open']:
                positive_price_volume += typical_price_volume_per_second
            elif row['close'] < row['open']:
                negative_price_volume += typical_price_volume_per_second
            else:
                if typical_price <= row['close']:
                    positive_price_volume += typical_price_volume_per_second
                else:
                    negative_price_volume += typical_price_volume_per_second
        print(f"positive_price_volume: {positive_price_volume}, negative_price_volume: {negative_price_volume}")
        return (positive_price_volume - negative_price_volume) 
    
    def calculate_mfi(self, positive_price_volume: float, negative_price_volume: float) -> float:
        """
        è®¡ç®—MFI
        
        Args:
            positive_price_volume: æ­£å‘ä»·æ ¼æˆäº¤é‡å’Œ
            negative_price_volume: è´Ÿå‘ä»·æ ¼æˆäº¤é‡å’Œ
        """
        return 100 - (100 / (1 + positive_price_volume / negative_price_volume))
    
    def calculate_net_inflow_obv(self, df: pd.DataFrame) -> pd.Series:
        """
        è®¡ç®—åŸºäºnet_inflowçš„OBVç±»ä¼¼æŒ‡æ ‡ï¼ˆç´¯ç§¯å‡€æµå…¥æŒ‡æ ‡ï¼‰
        
        Args:
            df: åŒ…å«net_inflowåˆ—çš„DataFrame
            
        Returns:
            pd.Series: ç´¯ç§¯å‡€æµå…¥æŒ‡æ ‡å€¼
        """
        if 'net_inflow' not in df.columns:
            return pd.Series(dtype=float)
        
        # ç´¯ç§¯net_inflowå€¼ï¼Œç±»ä¼¼OBVçš„ç´¯ç§¯æ–¹å¼
        obv_values = []
        cumulative_value = 0.0
        
        for net_inflow in df['net_inflow']:
            if pd.notna(net_inflow):
                cumulative_value += net_inflow
            obv_values.append(cumulative_value)
        
        return pd.Series(obv_values, index=df.index)
    
    def plot_with_mplfinance(self, df: pd.DataFrame, symbol: str, interval: str):
        """
        ä½¿ç”¨ mplfinance ç»˜åˆ¶æ›´ç¾è§‚çš„Kçº¿å›¾åŠMFIæŒ‡æ ‡ï¼Œå¹¶ä¿å­˜ä¸ºå›¾ç‰‡æ–‡ä»¶
        """
        try:
            mpf = importlib.import_module("mplfinance")
        except ImportError as exc:
            raise ImportError("è¯·å…ˆå®‰è£… mplfinanceï¼Œæ‰§è¡Œï¼špip install mplfinance") from exc

        if df.empty:
            print("æ•°æ®ä¸ºç©ºï¼Œæ— æ³•ç»˜åˆ¶å›¾è¡¨")
            return

        # ä¸»é¢æ¿åªåŒ…å«Kçº¿æ•°æ®ï¼Œä¸åŒ…å«volume
        plot_df = df[['timestamp', 'open', 'high', 'low', 'close']].copy()
        plot_df = plot_df.set_index('timestamp')
        plot_df.index.name = 'Date'
        plot_df.rename(columns={
            'open': 'Open',
            'high': 'High',
            'low': 'Low',
            'close': 'Close'
        }, inplace=True)

        add_plots = []
        
        # æ·»åŠ net_inflowåˆ°panel 1ï¼ˆä½¿ç”¨æŸ±çŠ¶å›¾ï¼Œå·¦ä¾§yè½´ï¼‰
        # æ­£æ•°ç»˜åˆ¶ç»¿è‰²ï¼Œè´Ÿæ•°ç»˜åˆ¶çº¢è‰²
        if 'net_inflow' in df.columns:
            net_inflow_series = df.set_index('timestamp')['net_inflow']
            
            # å°†net_inflowåˆ†æˆæ­£æ•°å’Œè´Ÿæ•°ä¸¤éƒ¨åˆ†
            positive_inflow = net_inflow_series.copy()
            positive_inflow[positive_inflow < 0] = 0  # åªä¿ç•™æ­£æ•°
            
            negative_inflow = net_inflow_series.copy()
            negative_inflow[negative_inflow > 0] = 0  # åªä¿ç•™è´Ÿæ•°
            
            # ç»˜åˆ¶æ­£æ•°ï¼ˆç»¿è‰²ï¼‰
            add_plots.append(
                mpf.make_addplot(positive_inflow, panel=1, type='bar', color='green', 
                               alpha=0.6, width=0.8, ylabel='å‡€æµå…¥', secondary_y=False)
            )
            
            # ç»˜åˆ¶è´Ÿæ•°ï¼ˆçº¢è‰²ï¼‰
            add_plots.append(
                mpf.make_addplot(negative_inflow, panel=1, type='bar', color='red', 
                               alpha=0.6, width=0.8, secondary_y=False)
            )
        
        # æ·»åŠ åŸºäºnet_inflowçš„OBVç±»ä¼¼æŒ‡æ ‡ï¼ˆåªè®¡ç®—æœ€è¿‘3å¤©çš„æ•°æ®ï¼‰
        if 'net_inflow' in df.columns:
            # åªä½¿ç”¨æœ€è¿‘3å¤©çš„æ•°æ®æ¥è®¡ç®—OBVæŒ‡æ ‡
            df_with_timestamp = df.copy()
            df_with_timestamp['timestamp'] = pd.to_datetime(df_with_timestamp['timestamp'])
            latest_time = df_with_timestamp['timestamp'].max()
            three_days_ago = latest_time - pd.Timedelta(days=self.history_periods[interval])
            df_3days = df_with_timestamp[df_with_timestamp['timestamp'] >= three_days_ago].copy()
            
            if not df_3days.empty and 'net_inflow' in df_3days.columns:
                # è®¡ç®—OBVæŒ‡æ ‡ï¼ˆåŸºäºæœ€è¿‘3å¤©çš„æ•°æ®ï¼Œä»3å¤©å‰çš„ç¬¬ä¸€ä¸ªå€¼å¼€å§‹ç´¯ç§¯ï¼‰
                obv_series_3days = self.calculate_net_inflow_obv(df_3days)
                
                # åˆ›å»ºå®Œæ•´çš„OBVåºåˆ—ï¼ˆ3å¤©å‰çš„æ•°æ®è®¾ä¸ºNaNï¼Œ3å¤©å†…çš„æ•°æ®ä½¿ç”¨è®¡ç®—å€¼ï¼‰
                df_indexed = df.set_index('timestamp')
                obv_full_series = pd.Series(index=df_indexed.index, dtype=float)
                df_3days_indexed = df_3days.set_index('timestamp')
                
                # ç¡®ä¿ç´¢å¼•å¯¹é½
                for idx in df_3days_indexed.index:
                    if idx in obv_full_series.index:
                        obv_idx = df_3days_indexed.index.get_loc(idx)
                        obv_full_series.loc[idx] = obv_series_3days.iloc[obv_idx]
                
                # æ·»åŠ åˆ°panel 1ï¼ˆä½¿ç”¨æŠ˜çº¿å›¾ï¼Œå·¦ä¾§yè½´ï¼Œä¸net_inflowå…±äº«ï¼‰
                add_plots.append(
                    mpf.make_addplot(obv_full_series, panel=1, color='darkorange', width=1.5, 
                                   label='Net Inflow OBV', secondary_y=False)
                )
        
        # æ·»åŠ MFIæŒ‡æ ‡åˆ°panel 1ï¼ˆä½¿ç”¨æŠ˜çº¿å›¾ï¼Œå³ä¾§yè½´ï¼‰
        if 'mfi' in df.columns:
            mfi_series = df.set_index('timestamp')['mfi']
            add_plots.append(
                mpf.make_addplot(mfi_series, panel=1, color='royalblue', width=1.2, 
                               ylabel='MFI', secondary_y=True)
            )
            add_plots.append(
                mpf.make_addplot(pd.Series(80, index=mfi_series.index), panel=1,
                                 color='purple', linestyle='--', width=0.8, 
                                secondary_y=True)
            )
            add_plots.append(
                mpf.make_addplot(pd.Series(20, index=mfi_series.index), panel=1,
                                 color='orange', linestyle='--', width=0.8, 
                                 secondary_y=True)
            )
        
        market_colors = mpf.make_marketcolors(up='green', down='red', inherit=True)
        mpf_style = mpf.make_mpf_style(base_mpf_style='yahoo', marketcolors=market_colors)

        save_path = f"{symbol}_{interval}_kline_mfi.png"
        
        # å…³é—­äº¤äº’æ¨¡å¼ï¼Œé˜²æ­¢æ˜¾ç¤ºå›¾ç‰‡ï¼ŒåŒæ—¶è·å–Figureå’ŒAxesè¿›è¡Œè‡ªå®šä¹‰æ ‡æ³¨
        plt.ioff()
        
        fig, axes = mpf.plot(
            plot_df,
            type='candle',
            style=mpf_style,
            volume=False,  # ä¸åœ¨ä¸»é¢æ¿æ˜¾ç¤ºvolume
            addplot=add_plots if add_plots else None,
            title=f'{symbol} {interval} Kçº¿ & å‡€æµå…¥ & MFI',
            figsize=(16, 10),
            panel_ratios=(3, 1) if add_plots else None,
            xrotation=20,
            tight_layout=True,
            datetime_format='%Y-%m-%d %H:%M',
            ylabel='ä»·æ ¼ (USDT)',
            returnfig=True
        )

        # ä¿å­˜å›¾ç‰‡
        fig.savefig(save_path, dpi=100, bbox_inches='tight', pad_inches=0.25)
        plt.close(fig)
        
        print(f"å›¾è¡¨å·²ä¿å­˜åˆ°: {save_path}")
    
    def load_history_from_csv(self) -> pd.DataFrame:
        """
        ä»CSVæ–‡ä»¶åŠ è½½å†å²Kçº¿å’ŒMFIæ•°æ®
        
        Returns:
            pandas.DataFrame: å†å²æ•°æ®ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©ºåˆ™è¿”å›ç©ºDataFrame
        """
        if not os.path.exists(self.csv_file_path):
            print(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {self.csv_file_path}")
            return pd.DataFrame()
        
        try:
            df = pd.read_csv(self.csv_file_path)
            if df.empty:
                print(f"CSVæ–‡ä»¶ä¸ºç©º: {self.csv_file_path}")
                return pd.DataFrame()
            
            # è½¬æ¢æ—¶é—´æˆ³ä¸ºdatetime
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            
            # ç¡®ä¿æ•°å€¼åˆ—ä¸ºæ•°å€¼ç±»å‹
            numeric_cols = ['open', 'high', 'low', 'close', 'volume', 'quote_volume', 'net_inflow', 'mfi']
            for col in numeric_cols:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
            
            # æŒ‰æ—¶é—´æ’åº
            df = df.sort_values('timestamp').reset_index(drop=True)
            
            print(f"ä»CSVæ–‡ä»¶åŠ è½½äº† {len(df)} æ¡å†å²è®°å½•")
            print(f"æ—¶é—´èŒƒå›´: {df['timestamp'].min()} åˆ° {df['timestamp'].max()}")
            
            return df
        except Exception as e:
            print(f"è¯»å–CSVæ–‡ä»¶å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def save_to_csv(self, df: pd.DataFrame):
        """
        ä¿å­˜Kçº¿å’ŒMFIæ•°æ®åˆ°CSVæ–‡ä»¶
        
        Args:
            df: åŒ…å«Kçº¿å’ŒMFIæ•°æ®çš„DataFrame
        """
        try:
            # ç¡®ä¿åŒ…å«æ‰€æœ‰å¿…è¦çš„åˆ—
            required_cols = ['timestamp', 'open', 'high', 'low', 'close', 'volume']
            if not all(col in df.columns for col in required_cols):
                print("æ•°æ®ç¼ºå°‘å¿…è¦çš„åˆ—ï¼Œæ— æ³•ä¿å­˜")
                return
            
            # é€‰æ‹©è¦ä¿å­˜çš„åˆ—
            save_cols = ['timestamp', 'open', 'high', 'low', 'close', 'volume']
            if 'quote_volume' in df.columns:
                save_cols.append('quote_volume')
            if 'net_inflow' in df.columns:
                save_cols.append('net_inflow')
            if 'mfi' in df.columns:
                save_cols.append('mfi')
            
            # æŒ‰æ—¶é—´æ’åºå¹¶å»é‡ï¼ˆä¿ç•™æœ€æ–°çš„è®°å½•ï¼‰
            df_save = df[save_cols].copy()
            df_save = df_save.sort_values('timestamp').drop_duplicates(subset=['timestamp'], keep='last')
            
            # ä¿å­˜åˆ°CSV
            df_save.to_csv(self.csv_file_path, index=False)
            print(f"æ•°æ®å·²ä¿å­˜åˆ° {self.csv_file_path}ï¼Œå…± {len(df_save)} æ¡è®°å½•")
        except Exception as e:
            print(f"ä¿å­˜CSVæ–‡ä»¶å¤±è´¥: {e}")



def send_dingtalk_message(webhook_url: str, message: str, title: str = "äº¤æ˜“ä¿¡å·æé†’"):
    """
    å‘é€é’‰é’‰æ¶ˆæ¯
    
    Args:
        webhook_url: é’‰é’‰æœºå™¨äººwebhookåœ°å€
        message: æ¶ˆæ¯å†…å®¹
        title: æ¶ˆæ¯æ ‡é¢˜
    """
    if not webhook_url:
        print("æœªé…ç½®é’‰é’‰webhookåœ°å€ï¼Œè·³è¿‡æ¶ˆæ¯å‘é€")
        return False
    
    try:
        data = {
            "msgtype": "markdown",
            "markdown": {
                "title": title,
                "text": f"## {title}\n\n{message}"
            }
        }
        
        response = requests.post(webhook_url, json=data, timeout=10)
        response.raise_for_status()
        result = response.json()
        
        if result.get('errcode') == 0:
            print(f"é’‰é’‰æ¶ˆæ¯å‘é€æˆåŠŸ: {title}")
            return True
        else:
            print(f"é’‰é’‰æ¶ˆæ¯å‘é€å¤±è´¥: {result.get('errmsg', 'æœªçŸ¥é”™è¯¯')}")
            return False
    except Exception as e:
        print(f"å‘é€é’‰é’‰æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
        return False


def detect_trading_signals(df: pd.DataFrame, binance: BinanceKlineData, symbol: str, interval: str, 
                          dingtalk_webhook: Optional[str] = None) -> Optional[Dict]:
    """
    æ£€æµ‹æœ€æ–°çš„äº¤æ˜“ä¿¡å·ï¼ˆåªæ£€æµ‹æœ€æ–°çš„ä¿¡å·ï¼Œé¿å…é‡å¤æ£€æµ‹å†å²ä¿¡å·ï¼‰
    
    Args:
        df: åŒ…å«mfiå’Œnet_inflowçš„DataFrame
        binance: BinanceKlineDataå®ä¾‹
        symbol: äº¤æ˜“å¯¹
        interval: æ—¶é—´é—´éš”
        dingtalk_webhook: é’‰é’‰webhookåœ°å€ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        Optional[Dict]: æ£€æµ‹åˆ°çš„æœ€æ–°äº¤æ˜“ä¿¡å·ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›None
    """
    if df.empty or 'mfi' not in df.columns or 'net_inflow' not in df.columns:
        print("æ•°æ®ä¸å®Œæ•´ï¼Œæ— æ³•æ£€æµ‹äº¤æ˜“ä¿¡å·")
        return None
    
    # è®¡ç®—net inflow obv
    obv_series = binance.calculate_net_inflow_obv(df)
    if obv_series.empty:
        print("æ— æ³•è®¡ç®—OBVæŒ‡æ ‡ï¼Œè·³è¿‡ä¿¡å·æ£€æµ‹")
        return None
    
    df_with_obv = df.copy()
    df_with_obv['net_inflow_obv'] = obv_series.values
    
    # éœ€è¦è‡³å°‘3æ¡æ•°æ®æ‰èƒ½åˆ¤æ–­è½¬æŠ˜ç‚¹ï¼ˆéœ€è¦å·¦å³ç›¸é‚»çš„æ•°æ®ï¼‰
    if len(df_with_obv) < 3:
        print("æ•°æ®ä¸è¶³ï¼Œæ— æ³•æ£€æµ‹è½¬æŠ˜ç‚¹")
        return None
    
    # åªæ£€æŸ¥æœ€åå‡ æ¡Kçº¿ï¼ˆæ£€æŸ¥å€’æ•°ç¬¬äºŒæ¡ï¼Œå› ä¸ºæœ€åä¸€æ¡å¯èƒ½æ²¡æœ‰ä¸‹ä¸€ä¸ªmfiå€¼ï¼‰
    # æ£€æŸ¥èŒƒå›´ï¼šä»å€’æ•°ç¬¬3æ¡åˆ°å€’æ•°ç¬¬2æ¡ï¼ˆç¡®ä¿æœ‰å·¦å³ç›¸é‚»æ•°æ®ï¼‰
    check_start = max(1, len(df_with_obv) - 3)
    check_end = len(df_with_obv) - 1
    
    # å…ˆéå†å†å²æ•°æ®ï¼Œæ‰¾åˆ°æ‰€æœ‰è½¬æŠ˜ç‚¹ï¼Œç”¨äºæ¯”è¾ƒOBVå€¼
    last_long_turn_point = None  # ä¸Šä¸€ä¸ªå¤šå¤´è½¬æŠ˜ç‚¹
    last_short_turn_point = None  # ä¸Šä¸€ä¸ªç©ºå¤´è½¬æŠ˜ç‚¹
    
    # éå†å†å²æ•°æ®ï¼ˆé™¤äº†æœ€åè¦æ£€æŸ¥çš„å‡ æ¡ï¼‰ï¼Œè®°å½•è½¬æŠ˜ç‚¹
    for i in range(1, check_start):
        if pd.isna(df_with_obv.iloc[i]['mfi']) or pd.isna(df_with_obv.iloc[i-1]['mfi']) or pd.isna(df_with_obv.iloc[i+1]['mfi']):
            continue
        
        current_mfi = df_with_obv.iloc[i]['mfi']
        prev_mfi = df_with_obv.iloc[i-1]['mfi']
        next_mfi = df_with_obv.iloc[i+1]['mfi']
        current_obv = df_with_obv.iloc[i]['net_inflow_obv']
        
        # è®°å½•å¤šå¤´è½¬æŠ˜ç‚¹
        if current_mfi < 30 and prev_mfi > current_mfi and next_mfi > current_mfi:
            last_long_turn_point = {
                'timestamp': df_with_obv.iloc[i]['timestamp'],
                'obv': current_obv
            }
        
        # è®°å½•ç©ºå¤´è½¬æŠ˜ç‚¹
        elif current_mfi > 70 and prev_mfi < current_mfi and next_mfi < current_mfi:
            last_short_turn_point = {
                'timestamp': df_with_obv.iloc[i]['timestamp'],
                'obv': current_obv
            }
    
    # åªæ£€æŸ¥æœ€æ–°çš„å‡ æ¡Kçº¿ï¼Œçœ‹æ˜¯å¦æœ‰æ–°çš„è½¬æŠ˜ç‚¹
    for i in range(check_start, check_end):
        if pd.isna(df_with_obv.iloc[i]['mfi']) or pd.isna(df_with_obv.iloc[i-1]['mfi']) or pd.isna(df_with_obv.iloc[i+1]['mfi']):
            continue
        
        current_mfi = df_with_obv.iloc[i]['mfi']
        prev_mfi = df_with_obv.iloc[i-1]['mfi']
        next_mfi = df_with_obv.iloc[i+1]['mfi']
        current_obv = df_with_obv.iloc[i]['net_inflow_obv']
        
        # æ£€æµ‹å¤šå¤´è½¬æŠ˜ç‚¹ï¼šmfi < 30ï¼Œä¸”å·¦å³ç›¸é‚»çš„mfiéƒ½å¤§äºå½“å‰mfi
        if current_mfi < 30 and prev_mfi > current_mfi and next_mfi > current_mfi:
            timestamp = df_with_obv.iloc[i]['timestamp']
            price = df_with_obv.iloc[i]['close']
            
            # å¦‚æœè¯¥è½¬æŠ˜ç‚¹çš„net inflow obvå€¼å¤§äºå‰ä¸€ä¸ªè½¬æŠ˜ç‚¹çš„net inflow obvå€¼ï¼Œåˆ™æç¤ºåšå¤š
            if last_long_turn_point is not None:
                last_obv = last_long_turn_point['obv']
                if current_obv > last_obv:
                    signal = {
                        'type': 'long',
                        'timestamp': timestamp,
                        'price': price,
                        'mfi': current_mfi,
                        'obv': current_obv,
                        'prev_obv': last_obv
                    }
                    
                    # å‘é€é’‰é’‰æ¶ˆæ¯
                    message = (
                        f"**åšå¤šä¿¡å·** ğŸŸ¢\n\n"
                        f"äº¤æ˜“å¯¹: {symbol}\n"
                        f"æ—¶é—´å‘¨æœŸ: {interval}\n"
                        f"æ—¶é—´: {timestamp}\n"
                        f"ä»·æ ¼: {price:.4f} USDT\n"
                        f"MFI: {current_mfi:.2f}\n"
                        f"å½“å‰OBV: {current_obv:.2f}\n"
                        f"å‰ä¸€ä¸ªè½¬æŠ˜ç‚¹OBV: {last_obv:.2f}\n"
                        f"OBVå¢é•¿: {current_obv - last_obv:.2f}"
                    )
                    
                    if dingtalk_webhook:
                        send_dingtalk_message(dingtalk_webhook, message, f"{symbol} åšå¤šä¿¡å·")
                    else:
                        print(f"\n{'='*50}")
                        print(f"åšå¤šä¿¡å·: {symbol} {interval}")
                        print(message)
                        print(f"{'='*50}\n")
                    
                    return signal
        
        # æ£€æµ‹ç©ºå¤´è½¬æŠ˜ç‚¹ï¼šmfi > 70ï¼Œä¸”å·¦å³ç›¸é‚»çš„mfiéƒ½å°äºå½“å‰mfi
        elif current_mfi > 70 and prev_mfi < current_mfi and next_mfi < current_mfi:
            timestamp = df_with_obv.iloc[i]['timestamp']
            price = df_with_obv.iloc[i]['close']
            
            # å¦‚æœè¯¥è½¬æŠ˜ç‚¹çš„net inflow obvå€¼å°äºå‰ä¸€ä¸ªè½¬æŠ˜ç‚¹çš„net inflow obvå€¼ï¼Œåˆ™æç¤ºåšç©º
            if last_short_turn_point is not None:
                last_obv = last_short_turn_point['obv']
                if current_obv < last_obv:
                    signal = {
                        'type': 'short',
                        'timestamp': timestamp,
                        'price': price,
                        'mfi': current_mfi,
                        'obv': current_obv,
                        'prev_obv': last_obv
                    }
                    
                    # å‘é€é’‰é’‰æ¶ˆæ¯
                    message = (
                        f"**åšç©ºä¿¡å·** ğŸ”´\n\n"
                        f"äº¤æ˜“å¯¹: {symbol}\n"
                        f"æ—¶é—´å‘¨æœŸ: {interval}\n"
                        f"æ—¶é—´: {timestamp}\n"
                        f"ä»·æ ¼: {price:.4f} USDT\n"
                        f"MFI: {current_mfi:.2f}\n"
                        f"å½“å‰OBV: {current_obv:.2f}\n"
                        f"å‰ä¸€ä¸ªè½¬æŠ˜ç‚¹OBV: {last_obv:.2f}\n"
                        f"OBVä¸‹é™: {last_obv - current_obv:.2f}"
                    )
                    
                    if dingtalk_webhook:
                        send_dingtalk_message(dingtalk_webhook, message, f"{symbol} åšç©ºä¿¡å·")
                    else:
                        print(f"\n{'='*50}")
                        print(f"åšç©ºä¿¡å·: {symbol} {interval}")
                        print(message)
                        print(f"{'='*50}\n")
                    
                    return signal
    
    return None


def calculate_net_inflow_and_mfi(binance: BinanceKlineData, df: pd.DataFrame, symbol: str, interval: str):
    """
    è®¡ç®—Kçº¿æ•°æ®çš„net_inflowå’ŒMFIå€¼
    
    Args:
        binance: BinanceKlineDataå®ä¾‹
        df: åŒ…å«Kçº¿æ•°æ®çš„DataFrame
        symbol: äº¤æ˜“å¯¹
        interval: æ—¶é—´é—´éš”
        
    Returns:
        pd.DataFrame: åŒ…å«net_inflowå’Œmfiçš„DataFrame
    """
    # è®¡ç®—net_inflow
    if 'net_inflow' not in df.columns:
        df['net_inflow'] = np.nan
    
    # æ ¹æ®intervalç¡®å®šæ¯ä¸ªKçº¿çš„æ—¶é—´è·¨åº¦ï¼ˆç§’ï¼‰
    interval_seconds_map = {
        '15m': 15 * 60,
        '1h': 3600,
        '4h': 4 * 3600,
        '1d': 86400
    }
    kline_seconds = interval_seconds_map.get(interval, 15 * 60)
    
    for i in range(df.index[0], df.index[-1] + 1):
        if pd.notna(df.loc[i, 'net_inflow']):
            # å¦‚æœå·²ç»æœ‰net_inflowå€¼ï¼Œè·³è¿‡
            continue
            
        candlestick_df = df.iloc[i:i+1]
        start_dt = pd.to_datetime(candlestick_df['timestamp'].iloc[0]).to_pydatetime()
        end_dt = start_dt + timedelta(seconds=kline_seconds-1)
        
        one_second_df = binance.get_kline_data(symbol=symbol, interval="1s", start_time=start_dt, end_time=end_dt)
        if one_second_df.empty:
            print(f"æœªèƒ½è·å– {symbol} çš„ {start_dt} ~ {end_dt} 1ç§’Kçº¿æ•°æ®")
            continue
        net_inflow = binance.calculate_typical_price_volume(one_second_df)
        print(f"timestamp: {start_dt}, net_inflow: {net_inflow}")
        df.loc[i, 'net_inflow'] = net_inflow
    
    # è®¡ç®—MFI
    if 'mfi' not in df.columns:
        df['mfi'] = np.nan
    
    window = 14
    mfi_values = []
    for i in range(df.index[0], df.index[-1] + 1):
        if pd.notna(df.loc[i, 'mfi']):
            mfi_values.append(float(df.loc[i, 'mfi']))
            continue
        
        # ä»…åœ¨æœ‰è¶³å¤Ÿçª—å£æ—¶è®¡ç®—
        if i < window - 1 or 'net_inflow' not in df.columns or pd.isna(df.loc[i, 'net_inflow']):
            mfi_values.append(float('nan'))
            continue
        
        window_net_inflow = df['net_inflow'].iloc[i - window + 1:i + 1]

        # æ­£å‘ä¸ºå¤§äºé›¶ã€è´Ÿå‘ä¸ºå°äºé›¶
        positive = window_net_inflow[window_net_inflow > 0].sum()
        negative = -window_net_inflow[window_net_inflow < 0].sum()  # è´Ÿæ•°è½¬æ­£

        if negative == 0:
            mfi = 100.0  # æç«¯æƒ…å†µå¤„ç†
        elif positive == 0:
            mfi = 0.0
        else:
            mfr = positive / negative
            mfi = 100 - (100 / (1 + mfr))
        mfi_values.append(mfi)
        print(f"timestamp: {df.loc[i, 'timestamp']}, positive: {positive}, negative: {negative}, mfi: {mfi}")
    
    df['mfi'] = mfi_values
    return df

def main():
    """ä¸»å‡½æ•°"""
    
    # é…ç½®å‚æ•°
    import argparse
    parser = argparse.ArgumentParser(description='å¸å®‰Kçº¿å‡€æµå…¥å’ŒMFIè®¡ç®—')
    parser.add_argument('--symbol', type=str, default="ETHUSDT", help='äº¤æ˜“å¯¹ï¼Œæ¯”å¦‚BTCUSDT, ETHUSDT')
    parser.add_argument('--interval', type=str, default="15m", help='æ—¶é—´é—´éš”ï¼ˆå¦‚1m, 5m, 15m, 1h, 4h, 1dç­‰ï¼‰')
    parser.add_argument('--dingtalk-webhook', type=str, default=None, 
                       help='é’‰é’‰æœºå™¨äººwebhookåœ°å€ï¼ˆå¯é€‰ï¼‰ï¼Œç”¨äºå‘é€äº¤æ˜“ä¿¡å·é€šçŸ¥')
    args = parser.parse_args()
    symbol = args.symbol
    interval = args.interval
    dingtalk_webhook = args.dingtalk_webhook or os.getenv('DINGTALK_WEBHOOK')

        # åˆ›å»ºå¸å®‰æ•°æ®è·å–å®ä¾‹
    csv_file_path = f"kline_mfi_history_{symbol}_{interval}.csv"
    binance = BinanceKlineData(csv_file_path=csv_file_path)
    
    # è¯»å–å†å²æ•°æ®
    print("æ­£åœ¨è¯»å–å†å²æ•°æ®...")
    history_df = binance.load_history_from_csv()
    
    # è®¡ç®—æœ€è¿‘çš„æ•´intervalæ—¶é—´
    now = datetime.now()
    interval_seconds = binance.interval_seconds[interval]
    end_time = datetime.fromtimestamp((int(now.timestamp()) // interval_seconds) * interval_seconds)

    history_period = binance.history_periods[interval]
    
    if history_df.empty:
        print(f"\nCSVæ–‡ä»¶ä¸ºç©ºï¼Œåˆå§‹åŒ–è¿‡å»{history_period}å¤©çš„æ•°æ®...")
        start_time = end_time - timedelta(days=history_period)
        end_time = end_time - timedelta(seconds=1)
        
        print(f"æ­£åœ¨è·å– {symbol} çš„ {interval} Kçº¿æ•°æ®...")
        print(f"æ—¶é—´èŒƒå›´: {start_time} åˆ° {end_time}\n")
        
        df = binance.get_kline_data(
            symbol=symbol,
            interval=interval,
            start_time=start_time,
            end_time=end_time
        )
        
        if df.empty:
            print("æœªèƒ½è·å–æ•°æ®ï¼Œç¨‹åºé€€å‡º")
            return
        
        # è®¡ç®—net_inflowå’ŒMFI
        df = calculate_net_inflow_and_mfi(binance, df, symbol, interval)
        
    else:
        # å¦‚æœä¸ä¸ºç©ºï¼Œè¯»å–æ–‡ä»¶ä¸­è¿‡å»3å¤©çš„å†å²å€¼
        print(f"\nCSVæ–‡ä»¶ä¸ä¸ºç©ºï¼Œè¯»å–è¿‡å»{history_period}å¤©çš„å†å²æ•°æ®...")
        history_start_time = end_time - timedelta(days=3)

        # ç¡®ä¿timestampæ˜¯datetimeç±»å‹
        history_df['timestamp'] = pd.to_datetime(history_df['timestamp'])
        
        # ç»Ÿä¸€æ—¶åŒºä¸ºå†å²æ•°æ®çš„timestampçš„æ—¶åŒº
        ts_tz = history_df['timestamp'].dt.tz
        recent_history = history_df[history_df['timestamp'] >= pd.Timestamp(history_start_time, tz=ts_tz)].copy()
        
        if recent_history.empty:
            print(f"å†å²æ•°æ®ä¸­æ²¡æœ‰è¿‡å»{history_period}å¤©çš„è®°å½•ï¼Œä½¿ç”¨å…¨éƒ¨å†å²æ•°æ®")
            recent_history = history_df.copy()
        else:
            print(f"ä»å†å²æ•°æ®ä¸­è¯»å–äº† {len(recent_history)} æ¡è¿‡å»{history_period}å¤©çš„è®°å½•")
        print(f"å†å²æ•°æ®æ—¶é—´èŒƒå›´: {recent_history['timestamp'].min()} åˆ° {recent_history['timestamp'].max()}")
        
        # ç¡®å®šéœ€è¦è¡¥å…¨çš„æ—¶é—´èŒƒå›´ï¼ˆåŸºäºå…¨éƒ¨å†å²æ•°æ®çš„æœ€æ–°æ—¶é—´ï¼‰
        latest_timestamp = history_df['timestamp'].max()
        new_df = pd.DataFrame()  # åˆå§‹åŒ–new_df
        fill_start_time = latest_timestamp + timedelta(seconds=interval_seconds)  # ä»ä¸‹ä¸€æ¡å¼€å§‹
        fill_start_time = pd.to_datetime(fill_start_time).to_pydatetime().replace(tzinfo=None)
        
        if fill_start_time < end_time:
            # éœ€è¦è¡¥å…¨ä»latest_timestampåˆ°end_timeçš„æ•°æ®
            print(f"\néœ€è¦è¡¥å…¨ä» {fill_start_time} åˆ° {end_time} çš„æ•°æ®...")
            
            # è·å–ç¼ºå¤±æ—¶é—´æ®µçš„æ•°æ®
            
            end_time = end_time - timedelta(seconds=1)
            
            new_df = binance.get_kline_data(
                symbol=symbol,
                interval=interval,
                start_time=fill_start_time,
                end_time=end_time
            )
            
            if not new_df.empty:
                print(f"è·å–äº† {len(new_df)} æ¡æ–°æ•°æ®")
                df_for_calc = pd.concat([recent_history, new_df], ignore_index=True)
                df_for_calc = df_for_calc.sort_values('timestamp').reset_index(drop=True)
                # å»é‡ï¼Œä¿ç•™æœ€æ–°çš„
                df_for_calc = df_for_calc.drop_duplicates(subset=['timestamp'], keep='last')
            else:
                print("æœªèƒ½è·å–æ–°æ•°æ®ï¼Œä½¿ç”¨å†å²æ•°æ®")
                df_for_calc = recent_history.copy()
        else:
            # å†å²æ•°æ®å·²ç»æ˜¯æœ€æ–°çš„ï¼Œç›´æ¥ä½¿ç”¨
            print("å†å²æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€è¡¥å…¨")
            df_for_calc = recent_history.copy()
        
        # è®¡ç®—ç¼ºå¤±çš„net_inflowå’ŒMFIï¼ˆåŸºäºè¿‡å»7å¤©+æ–°æ•°æ®ï¼‰
        df_for_calc = calculate_net_inflow_and_mfi(binance, df_for_calc, symbol, interval)
        
        # å°†è®¡ç®—ç»“æœåˆå¹¶å›å®Œæ•´çš„å†å²æ•°æ®
        # ä½¿ç”¨mergeæ›´æ–°å†å²æ•°æ®ä¸­å·²æœ‰çš„è®°å½•ï¼Œå¹¶æ·»åŠ æ–°è®°å½•
        if 'net_inflow' in df_for_calc.columns or 'mfi' in df_for_calc.columns:
            # ä½¿ç”¨mergeæ›´æ–°net_inflowå’Œmfi
            update_cols = ['timestamp']
            if 'net_inflow' in df_for_calc.columns:
                update_cols.append('net_inflow')
            if 'mfi' in df_for_calc.columns:
                update_cols.append('mfi')
            
            # æ›´æ–°å†å²æ•°æ®ä¸­å·²æœ‰çš„è®°å½•
            history_df = history_df.merge(
                df_for_calc[update_cols], 
                on='timestamp', 
                how='left', 
                suffixes=('', '_new')
            )
            
            # ç”¨æ–°å€¼æ›¿æ¢æ—§å€¼
            if 'net_inflow_new' in history_df.columns:
                history_df['net_inflow'] = history_df['net_inflow_new'].fillna(history_df['net_inflow'])
                history_df = history_df.drop(columns=['net_inflow_new'])
            if 'mfi_new' in history_df.columns:
                history_df['mfi'] = history_df['mfi_new'].fillna(history_df['mfi'])
                history_df = history_df.drop(columns=['mfi_new'])
        
        # æ·»åŠ æ–°è®°å½•ï¼ˆåœ¨df_for_calcä¸­ä½†ä¸åœ¨history_dfä¸­ï¼‰
        existing_timestamps = set(history_df['timestamp'])
        new_records = df_for_calc[~df_for_calc['timestamp'].isin(existing_timestamps)]
        
        if not new_records.empty:
            # ç¡®ä¿æ–°è®°å½•åŒ…å«æ‰€æœ‰å¿…è¦çš„åˆ—
            required_cols = ['timestamp', 'open', 'high', 'low', 'close', 'volume']
            for col in required_cols:
                if col not in new_records.columns and col in df_for_calc.columns:
                    pass  # åˆ—å·²å­˜åœ¨
                elif col not in new_records.columns:
                    # å¦‚æœæ–°è®°å½•ç¼ºå°‘å¿…è¦çš„åˆ—ï¼Œå°è¯•ä»df_for_calcè·å–
                    if col in df_for_calc.columns:
                        new_records[col] = df_for_calc.loc[new_records.index, col]
            
            # åˆå¹¶æ–°è®°å½•
            df = pd.concat([history_df, new_records], ignore_index=True)
        else:
            df = history_df.copy()
        
        # æŒ‰æ—¶é—´æ’åºå¹¶å»é‡
        df = df.sort_values('timestamp').reset_index(drop=True)
        df = df.drop_duplicates(subset=['timestamp'], keep='last')
    
    print(f"\næœ€ç»ˆæ•°æ®é¢„è§ˆ:")
    print(df.head())
    print(f"\næ•°æ®ç»Ÿè®¡:")
    print(df.describe())
    
    # ä¿å­˜åˆ°CSV
    print("\næ­£åœ¨ä¿å­˜æ•°æ®åˆ°CSV...")
    binance.save_to_csv(df)
    
    # ä½¿ç”¨mplfinanceç»˜åˆ¶æ›´ç¾è§‚çš„å›¾è¡¨
    print("\næ­£åœ¨ç”Ÿæˆå›¾è¡¨...")
    if 'timestamp' in df.columns:
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        latest_time = df['timestamp'].max()
        history_period_time = latest_time - pd.Timedelta(days=history_period)
        df_last = df[df['timestamp'] >= history_period_time].copy()
    else:
        df_last = df.copy()
    binance.plot_with_mplfinance(df_last, symbol, interval)
    
    # æ£€æµ‹æœ€æ–°çš„äº¤æ˜“ä¿¡å·ï¼ˆåªæ£€æµ‹æœ€æ–°ä¿¡å·ï¼Œé¿å…é‡å¤æ£€æµ‹å†å²ä¿¡å·ï¼‰
    print("\næ­£åœ¨æ£€æµ‹æœ€æ–°äº¤æ˜“ä¿¡å·...")
    if 'timestamp' in df.columns:
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        # ä½¿ç”¨è¶³å¤Ÿçš„å†å²æ•°æ®æ¥æ‰¾åˆ°å‰ä¸€ä¸ªè½¬æŠ˜ç‚¹è¿›è¡Œæ¯”è¾ƒ
        # ä½†åªæ£€æµ‹æœ€æ–°çš„å‡ æ¡Kçº¿
        latest_time = df['timestamp'].max()
        signal_check_time = latest_time - pd.Timedelta(days=7)
        df_for_signal = df[df['timestamp'] >= signal_check_time].copy()
    else:
        df_for_signal = df.copy()
    
    if not df_for_signal.empty and 'mfi' in df_for_signal.columns and 'net_inflow' in df_for_signal.columns:
        signal = detect_trading_signals(df_for_signal, binance, symbol, interval, dingtalk_webhook)
        if signal:
            print(f"\næ£€æµ‹åˆ°æœ€æ–°äº¤æ˜“ä¿¡å·: {signal['type']} ä¿¡å·")
        else:
            print("æœªæ£€æµ‹åˆ°æœ€æ–°äº¤æ˜“ä¿¡å·")
    else:
        print("æ•°æ®ä¸å®Œæ•´ï¼Œè·³è¿‡äº¤æ˜“ä¿¡å·æ£€æµ‹")


if __name__ == "__main__":
    main()

